{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocessing as PRE\n",
    "import feature_engineering as FE\n",
    "import load_data as LD\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import ElasticNet, Lasso, BayesianRidge, LassoLarsIC, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "import sklearn.pipeline as pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV as GSCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(a, b):\n",
    "    \n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    \n",
    "    error = b - a \n",
    "    square = (b - a) ** 2\n",
    "    mean = np.mean(square)\n",
    "    root = np.sqrt(mean)\n",
    "    \n",
    "    return(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    score = rmse(y_pred, y_test)\n",
    "    return(score, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_params(model, params, X_train, y_train, cv=5):\n",
    "    clf = GSCV(model, params, cv=cv)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    best_params = clf.best_params_\n",
    "    results = clf.cv_results_.items()\n",
    "     \n",
    "    return(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training, Validation, and Testing sets\n",
    "X_train, y_train, X_test, y_test = LD.load_data(outliers=True, frac=0.2, scale=True, test_frac=0.4)\n",
    "df_val_test = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "X_val, y_val, X_test, y_test = LD.split_train_val(df_val_test, test_frac=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "params_linear = {'alpha':[0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 0.6, 0.7, 0.8, 0.9]}\n",
    "lasso = Lasso(**get_best_params(Lasso(), params_linear, X_train, y_train, cv=4))\n",
    "ridge = Ridge(**get_best_params(Ridge(), params_linear, X_train, y_train, cv=4))\n",
    "\n",
    "params_linear_net = {'alpha':[0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 0.6, 0.7, 0.8, 0.9], \n",
    "                     'l1_ratio':[0.1, 0.3, 0.5, 0.7, 0.9]}\n",
    "enet = ElasticNet(**get_best_params(ElasticNet(), params_linear_net, X_train, y_train, cv=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kernel Ridge Regressions\n",
    "params_kernel_ridge = {'alpha':[0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 0.6, 0.7, 0.8, 0.9], \n",
    "                      'kernel':['linear', 'polynomial'], 'degree':[1, 2, 3, 4]}\n",
    "kernel_ridge = KernelRidge(**get_best_params(KernelRidge(), params_kernel_ridge, X_train, y_train, cv=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "params_rf = {'max_depth':[2, 3, 4, 5, 6], 'n_estimators':[50, 100, 200, 300, 400, 500, 750], 'n_jobs':[-1]}\n",
    "rf = RandomForestRegressor(**get_best_params(RandomForestRegressor(), params_rf, X_train, y_train, cv=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_gboost = {'n_estimators':[1000, 2000, 3000, 4000, 5000], 'learning_rate':[ 0.05, 0.1, 0.2], \n",
    "                 'min_samples_leaf':[5, 10, 15, 20], 'min_samples_split':[5, 10, 15, 20], 'loss':['huber']}\n",
    "gboost = GradientBoostingRegressor(**get_best_params(GradientBoostingRegressor(), params_gboost, X_train, y_train, cv=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n",
    "                             learning_rate=0.05, max_depth=3, \n",
    "                             min_child_weight=1.7817, n_estimators=2200,\n",
    "                             reg_alpha=0.4640, reg_lambda=0.8571,\n",
    "                             subsample=0.5213, silent=1,\n",
    "                             random_state =7, nthread = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=5,\n",
    "                              learning_rate=0.05, n_estimators=720,\n",
    "                              max_bin = 55, bagging_fraction = 0.8,\n",
    "                              bagging_freq = 5, feature_fraction = 0.2319,\n",
    "                              feature_fraction_seed=9, bagging_seed=9,\n",
    "                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All models\n",
    "model_names = ['Lasso', 'Ridge', 'Kernel Ridge', 'Random Forest', 'Gradient Boosting', 'XG Boost', 'Light GB']\n",
    "model_list = [lasso, ridge, kernel_ridge, rf, gboost, model_xgb, model_lgb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_list = []\n",
    "pred_list = []\n",
    "\n",
    "for model, name in zip(model_list, model_names):\n",
    "    model.fit(X_train, y_train)\n",
    "    score, pred = get_score(model, X_val, y_val)\n",
    "    \n",
    "    score_list.append(score)\n",
    "    pred_list.append(pred)\n",
    "    \n",
    "    print(f'{name} \\n{score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Scores\n",
      "0.12547395778163944\n",
      "0.11972912062438024\n",
      "0.12174525897677237\n"
     ]
    }
   ],
   "source": [
    "print('Validation Scores')\n",
    "pred_list = []\n",
    "for model in [lasso, ridge, enet]:\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    score, pred = get_score(model, X_val, y_val)\n",
    "    \n",
    "    pred_list.append(pred)\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Scores\n",
      "0.13596039116052264\n",
      "0.13700377483737983\n",
      "0.13533984829670617\n"
     ]
    }
   ],
   "source": [
    "print('Testing Scores')\n",
    "pred_list_test = []\n",
    "for model in [lasso, ridge, enet]:\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    score, pred = get_score(model, X_test, y_test)\n",
    "    pred_list_test.append(pred)\n",
    "    \n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta ModeL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.0005, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Meta\n",
    "meta_features = pd.DataFrame({'Lasso':pred_list[0], 'Ridge':pred_list[1], 'ENet':pred_list[2]})\n",
    "meta_model = Lasso(**get_best_params(Lasso(), params_linear, meta_features, y_val, cv=4))\n",
    "meta_model.fit(meta_features, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta Model Testing Score\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1329324749907174"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_meta = pd.DataFrame({'Lasso':pred_list_test[0], 'Ridge':pred_list_test[1], 'ENet':pred_list_test[2]})\n",
    "score, pred = get_score(meta_model, X_test_meta, y_test)\n",
    "print('Meta Model Testing Score')\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25755.52588186906"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = meta_model.predict(X_test_meta)\n",
    "y = y_test\n",
    "\n",
    "rmse(np.exp(yhat), np.exp(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007584512141128519"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.abs((yhat - y) / y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel Reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params_kernel_ridge = {'alpha':[0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 0.6, 0.7, 0.8, 0.9], \n",
    "#                       'kernel':['linear', 'polynomial'], 'degree':[1, 2, 3, 4]}\n",
    "# kernel_ridge = KernelRidge(**get_best_params(KernelRidge(), params_kernel_ridge, X_train, y_train, cv=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
